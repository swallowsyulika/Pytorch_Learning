{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Net(\n",
      "  (fc1): Linear(in_features=784, out_features=64, bias=True)\n",
      "  (fc2): Linear(in_features=64, out_features=64, bias=True)\n",
      "  (fc3): Linear(in_features=64, out_features=64, bias=True)\n",
      "  (fc4): Linear(in_features=64, out_features=10, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "from torchvision import transforms, datasets\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "train = datasets.MNIST(\"\", train=True, download=True, \n",
    "                      transform=transforms.Compose([transforms.ToTensor()]))\n",
    "test = datasets.MNIST(\"\", train=False, download=True, \n",
    "                      transform=transforms.Compose([transforms.ToTensor()]))\n",
    "\n",
    "trainset = torch.utils.data.DataLoader(train, batch_size=10, shuffle=True)\n",
    "testset = torch.utils.data.DataLoader(test, batch_size=10, shuffle=True)\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        # full conntcted layer with input 784(flatten from 28*28)\n",
    "        # we will make three hidden layer with 64, so output will be 64\n",
    "        # final output will be 10\n",
    "        self.fc1 = nn.Linear(784, 64)    # input layer\n",
    "        self.fc2 = nn.Linear(64, 64)\n",
    "        self.fc3 = nn.Linear(64, 64)\n",
    "        self.fc4 = nn.Linear(64, 10)    # output layer \n",
    "        \n",
    "    def forward(self, x):\n",
    "        # pass data through all layer with activation function\n",
    "        # and \n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = F.relu(self.fc3(x))\n",
    "        x = self.fc4(x)\n",
    "        \n",
    "        return F.log_softmax(x, dim=1)\n",
    "\n",
    "net = Net()\n",
    "print(net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.0975, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0134, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0738, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0067, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0401, grad_fn=<NllLossBackward>)\n"
     ]
    }
   ],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "optimizer = optim.Adam(net.parameters(), lr=0.001)    # lr = learning rate, 0.001 = 1e-3\n",
    "\n",
    "epochs = 5\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    for data in trainset:\n",
    "        # data is a batch of featuresets and labels\n",
    "        X, y = data\n",
    "        net.zero_grad()\n",
    "        output = net(X.view(-1, 28*28))\n",
    "        loss = F.nll_loss(output, y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    print(loss)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ACC -> 0.979%\n"
     ]
    }
   ],
   "source": [
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    for data in trainset:\n",
    "        X, y = data\n",
    "        output = net(X.view(-1, 784))\n",
    "        for i, ele in enumerate(output):\n",
    "            if torch.argmax(ele) == y[i]:\n",
    "                correct += 1\n",
    "            total += 1\n",
    "            \n",
    "print(f\"ACC -> {round(correct/total, 3)}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x1ee6f9d7a90>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.imshow(X[0].view(28, 28))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(9)\n"
     ]
    }
   ],
   "source": [
    "print(torch.argmax(net(X.view(-1, 28*28))[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
